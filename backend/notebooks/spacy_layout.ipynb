{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "004d4f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jacob\\repos\\study-buddy\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy_layout import spaCyLayout\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad941754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_table(df: pd.DataFrame):\n",
    "    return df.to_markdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c81d405",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "layout = spaCyLayout(nlp, display_table=render_table) \n",
    "\n",
    "file = \"test_docs/Jacob Kerner Resume.docx\"\n",
    "doc = layout(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a915d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jacob Kerner\\n\\njacobkerner@gmail(406)-868-3798\\n\\nWORK EXPERIENCE\\n\\nPfizer\\t\\t\\t\\t\\t\\t\\t\\t\\t        \\t\\t            March 2023 – Current\\n\\nMachine Learning Engineer/Lead\\t\\t\\t\\t\\t\\t\\t\\t      New York City, NY\\n\\nDeveloped an enterprise-wide PII redaction service collaborating with legal and compliance to standardize data sources to comply with GxP and HIPAA regulations.\\n\\nOversaw the development of an internal GenAI no-code workflow builder and document authoring app adopted by over 1,000 users, reducing external vendor costs and reducing first draft document creation time.\\n\\nPrototyped and deployed multiple agentic workflows for automation including SQL generation, document review, and production quality monitoring built using both Azure AI Foundry and LangGraph.\\n\\nTested various OCR and embedding/vector database solutions prior to implementation within an enterprise RAG service to reduce external vendor costs by $50k monthly.\\n\\nServed as technical lead for the creation of an enterprise platform to provide real time guardrails monitoring and metrics for all LLM based solutions including PII monitoring, toxicity, truthfulness, and other metrics.\\n\\nInternalized third party vendor solutions within enterprise AWS accounts ensuring legal and security compliance.\\n\\nCustom trained a SpaCy NLP pipeline for clinical text recognition and tagging to replace a licensed solution reducing costs by ~$30k a month.\\n\\nAwards:\\n\\nAI Champion, I led various global workshops and office hours for internal tools to drive adoption of AI tools globally across the enterprise.\\n\\nSyneos Health\\t\\t\\t\\t\\t\\t\\t\\t\\t      \\tNovember 2021 – March 2023\\n\\nAI and Machine Learning Specialist\\t\\t\\t\\t\\t\\t\\t     \\t           Morrisville, NC\\n\\nWorked to develop an internal tool utilizing a custom trained Spacy pipeline for named entity recognition to replace $500k/year vendor application.\\n\\nCreated internal tool to automate data extraction and processing from ClinicalTrials.gov to replace current methods to reduce cost and turnaround time.\\n\\nPerformed data analysis on RWE patient healthcare data and trained various supervised and unsupervised ML models for prediction of patient outcome based on healthcare data.\\n\\nWorked within Syneos Health and contract sponsors to help establish machine learning groups within each company.\\n\\nPresented findings/methods at multiple clinical research conferences.\\n\\nCase Western Reserve University\\t\\t\\t\\t\\t\\t\\t       July 2019– October 2021\\n\\nGraduate Research Assistant-Biomedical Engineering\\t\\t\\t\\t\\t\\t\\tCleveland, OH\\n\\nCreated machine learning model and application to expedite the development of drug releasing materials utilizing common frameworks including TensorFlow, Keras, and scikit-learn.\\n\\nAuthored several presentations and first author publications.\\n\\nEDUCATION\\n\\nCase Western Reserve University\\t\\t\\t                     \\t        \\t\\t      \\t         December, 2021\\n\\nMS, Biomedical Engineering\\t\\t\\t\\t\\t\\t\\t   \\t\\t \\tCleveland, OH\\n\\nMontana State University\\t\\t\\t\\t                     \\t        \\t\\t    \\t\\t      May, 2019\\n\\nBS, Chemical Engineering/BS, Biological Engineering\\t\\t\\t\\t\\t \\t\\t  Bozeman, MT\\n\\nSKILLS\\n\\nProgramming and ML:\\n\\nPython, R, Pandas, Spacy, Tensorflow, PyTorch, Scikit-learn, LangChain, LangGraph, Generative AI, FastAPI\\n\\nMLOps and Cloud:\\n\\nAWS, Git, Azure, Docker, CI/CD\\n\\nNontechnical:\\n\\nProject Management, Technical Writing, Presentations\\n\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7eeb3070",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'page_no'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m pages = []\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdoc\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpages\u001b[49m:\n\u001b[32m      4\u001b[39m     pages.append(page)\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(page[\u001b[32m0\u001b[39m].page_no)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jacob\\repos\\study-buddy\\.venv\\Lib\\site-packages\\spacy\\tokens\\underscore.py:51\u001b[39m, in \u001b[36mUnderscore.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m     49\u001b[39m default, method, getter, setter = \u001b[38;5;28mself\u001b[39m._extensions[name]\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m getter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgetter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     53\u001b[39m     method_partial = functools.partial(method, \u001b[38;5;28mself\u001b[39m._obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jacob\\repos\\study-buddy\\.venv\\Lib\\site-packages\\spacy_layout\\layout.py:218\u001b[39m, in \u001b[36mspaCyLayout.get_pages\u001b[39m\u001b[34m(self, doc)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m span \u001b[38;5;129;01min\u001b[39;00m doc.spans[\u001b[38;5;28mself\u001b[39m.attrs.span_group]:\n\u001b[32m    217\u001b[39m     span_layout = span._.get(\u001b[38;5;28mself\u001b[39m.attrs.span_layout)\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m     page_spans[\u001b[43mspan_layout\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpage_no\u001b[49m].append(span)\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [(pages[i], page_spans[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m page_spans]\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'page_no'"
     ]
    }
   ],
   "source": [
    "pages = []\n",
    "\n",
    "for page in doc._.pages:\n",
    "    pages.append(page)\n",
    "    print(page[0].page_no)\n",
    "type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "80356f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f367d67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference the sections and figures you are dicussing here\n",
      "1019 to 2737\n",
      "|    | 0                                                                                | 1   |\n",
      "|---:|:---------------------------------------------------------------------------------|:----|\n",
      "|  0 | 13 Discussion                                                                    | 10  |\n",
      "|  1 | 14 Conclusions                                                                   | 11  |\n",
      "|  2 | 15 Acknowledgments                                                               | 11  |\n",
      "|  3 | 16 References                                                                    | 11  |\n",
      "|  4 | #Please know that you can use a html output but you need to keep the sectioning. |     |\n",
      "|  5 | #Please Reference your figures and tables so that it is readable                 |     |\n",
      "|  6 | #Each update is important to keep for grading                                    |     |\n",
      "\n",
      "1 Update 6\n",
      "\n",
      "Please put a bulleted list of things you have accomplished since the last update\n",
      "\n",
      "-Include things that didn't work but you tried\n",
      "\n",
      "-Questions that you might have on your project.\n",
      "\n",
      "-Things you are planning on doing\n",
      "\n",
      "Reference the sections and figures you are dicussing here\n",
      "\n",
      "2 Update 5\n",
      "\n",
      "Please put a bulleted list of things you have accomplished since the last update\n",
      "\n",
      "-Include things that didn't work but you tried\n",
      "\n",
      "-Questions that you might have on your project.\n",
      "\n",
      "-Things you are planning on doing\n",
      "\n",
      "Reference the sections and figures you are dicussing here\n",
      "\n",
      "3 Update 4\n",
      "\n",
      "Please put a bulleted list of things you have accomplished since the last update\n",
      "\n",
      "-Include things that didn't work but you tried\n",
      "\n",
      "-Questions that you might have on your project.\n",
      "\n",
      "-Things you are planning on doing\n",
      "\n",
      "Reference the sections and figures you are dicussing here\n"
     ]
    }
   ],
   "source": [
    "page = pages[1]\n",
    "page_spans = page[1]\n",
    "page_start = page_spans[0].start_char\n",
    "print(page_spans[-1])\n",
    "page_end = page_spans[-1].end_char\n",
    "print(str(page_start) + \" to \" + str(page_end))\n",
    "md = doc.text\n",
    "print(md[page_start:page_end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f027bdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3d723ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "md = doc.text\n",
    "page_1 = md[page_start:page_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "14874bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Predictors of Binding Affinity Between Small Molecule Drugs and Model Polymers\\n\\nJacob Kerner\\n\\n12 March, 2021\\n\\nContents\\n\\n|    | 0                                  |   1 |\\n|---:|:-----------------------------------|----:|\\n|  0 | 1 Update 6                         |   2 |\\n|  1 | 2 Update 5                         |   2 |\\n|  2 | 3 Update 4                         |   2 |\\n|  3 | 4 Update 3                         |   3 |\\n|  4 | 5 Update 2                         |   3 |\\n|  5 | 6 Update 1                         |   4 |\\n|  6 | 7 Excuetive Summary                |   5 |\\n|  7 | 8 Abstract                         |   5 |\\n|  8 | 9 Introduction                     |   5 |\\n|  9 | 10 Data Science Methods            |   6 |\\n| 10 | 11 Exploratory Data Analysis       |   6 |\\n| 11 | 11.1 Explanation of your data set  |   6 |\\n| 12 | 11.2 Data Cleaning . . . . . . . . |   6 |\\n| 13 | 11.3 Data Vizualizations . . . . . |  10 |\\n| 14 | 11.4 Variable Correlations . . . . |  10 |\\n\\n12 Statistical Learning: Modeling & Prediction'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
