{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "004d4f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy_layout import spaCyLayout\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ad941754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_table(df: pd.DataFrame):\n",
    "    return df.to_markdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4c81d405",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "[E047] Can't assign a value to unregistered extension attribute 'file_name'. Did you forget to call the `set_extension` method?",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[149]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m file = \u001b[33m\"\u001b[39m\u001b[33mtest_docs/projectreport3-jjk252.pdf\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m doc = layout(file)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mdoc\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfile_name\u001b[49m = file\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jacob\\repos\\study-buddy\\.venv\\Lib\\site-packages\\spacy\\tokens\\underscore.py:76\u001b[39m, in \u001b[36mUnderscore.__setattr__\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m, value: Any):\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._extensions:\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(Errors.E047.format(name=name))\n\u001b[32m     77\u001b[39m     default, method, getter, setter = \u001b[38;5;28mself\u001b[39m._extensions[name]\n\u001b[32m     78\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m setter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mAttributeError\u001b[39m: [E047] Can't assign a value to unregistered extension attribute 'file_name'. Did you forget to call the `set_extension` method?"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "layout = spaCyLayout(nlp, display_table=render_table) \n",
    "\n",
    "file = \"test_docs/projectreport3-jjk252.pdf\"\n",
    "doc = layout(file)\n",
    "doc._.file_name = file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "74a915d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors of Binding Affinity Between Small Molecule Drugs and Model Polymers\n",
      "\n",
      "Jacob Kerner\n",
      "\n",
      "12 March, 2021\n",
      "\n",
      "Contents\n",
      "\n",
      "|    | 0                                  |   1 |\n",
      "|---:|:-----------------------------------|----:|\n",
      "|  0 | 1 Update 6                         |   2 |\n",
      "|  1 | 2 Update 5                         |   2 |\n",
      "|  2 | 3 Update 4                         |   2 |\n",
      "|  3 | 4 Update 3                         |   3 |\n",
      "|  4 | 5 Update 2                         |   3 |\n",
      "|  5 | 6 Update 1                         |   4 |\n",
      "|  6 | 7 Excuetive Summary                |   5 |\n",
      "|  7 | 8 Abstract                         |   5 |\n",
      "|  8 | 9 Introduction                     |   5 |\n",
      "|  9 | 10 Data Science Methods            |   6 |\n",
      "| 10 | 11 Exploratory Data Analysis       |   6 |\n",
      "| 11 | 11.1 Explanation of your data set  |   6 |\n",
      "| 12 | 11.2 Data Cleaning . . . . . . . . |   6 |\n",
      "| 13 | 11.3 Data Vizualizations . . . . . |  10 |\n",
      "| 14 | 11.4 Variable Correlations . . . . |  10 |\n",
      "\n",
      "12 Statistical Learning: Modeling & Prediction\n",
      "\n",
      "|    | 0                                                                                | 1   |\n",
      "|---:|:---------------------------------------------------------------------------------|:----|\n",
      "|  0 | 13 Discussion                                                                    | 10  |\n",
      "|  1 | 14 Conclusions                                                                   | 11  |\n",
      "|  2 | 15 Acknowledgments                                                               | 11  |\n",
      "|  3 | 16 References                                                                    | 11  |\n",
      "|  4 | #Please know that you can use a html output but you need to keep the sectioning. |     |\n",
      "|  5 | #Please Reference your figures and tables so that it is readable                 |     |\n",
      "|  6 | #Each update is important to keep for grading                                    |     |\n",
      "\n",
      "1 Update 6\n",
      "\n",
      "Please put a bulleted list of things you have accomplished since the last update\n",
      "\n",
      "-Include things that didn't work but you tried\n",
      "\n",
      "-Questions that you might have on your project.\n",
      "\n",
      "-Things you are planning on doing\n",
      "\n",
      "Reference the sections and figures you are dicussing here\n",
      "\n",
      "2 Update 5\n",
      "\n",
      "Please put a bulleted list of things you have accomplished since the last update\n",
      "\n",
      "-Include things that didn't work but you tried\n",
      "\n",
      "-Questions that you might have on your project.\n",
      "\n",
      "-Things you are planning on doing\n",
      "\n",
      "Reference the sections and figures you are dicussing here\n",
      "\n",
      "3 Update 4\n",
      "\n",
      "Please put a bulleted list of things you have accomplished since the last update\n",
      "\n",
      "-Include things that didn't work but you tried\n",
      "\n",
      "-Questions that you might have on your project.\n",
      "\n",
      "-Things you are planning on doing\n",
      "\n",
      "Reference the sections and figures you are dicussing here\n",
      "\n",
      "4 Update 3\n",
      "\n",
      "Current work:\n",
      "\n",
      "-.sdf files were for all molecules in dataset were downloaded from pubchem\n",
      "\n",
      "∗ Custom scripts making use of pubchempy to download were used from previous work\n",
      "\n",
      "-Descriptors for molecules were calculated from .sdf files using PaDEL\n",
      "\n",
      "-Descriptors were combined based on host/guest combination\n",
      "\n",
      "∗ Paired with binding affinity\n",
      "\n",
      "-Dataset is now in final complete form\n",
      "\n",
      "Plans for next update:\n",
      "\n",
      "-Calculate correlation between descriptors\n",
      "\n",
      "-Create models using subset techniques to determine best descriptors\n",
      "\n",
      "∗ Possible way to limit dimensionality of models\n",
      "\n",
      "Questions:\n",
      "\n",
      "-No questions at the moment\n",
      "\n",
      "5 Update 2\n",
      "\n",
      "I've addressed comments on my previous submission in the introduction portion of this submission. I hope this is sufficient in answering any questions that were previously noted.\n",
      "\n",
      "Current work:\n",
      "\n",
      "-Data was reformated into a single table with polymer types as a column.\n",
      "\n",
      "-Data was reformated to remove whitespace as well as remove different casses, columns were renamed for ease of accesing\n",
      "\n",
      "-Several issues were manually fixed such as some columns being merged in random portions and errors in the data table itself such as mispositioned column entries.\n",
      "\n",
      "-Since the end goal of the model is to predit affinity in biological conditions, temperature, solvent, and pH should be similar to biologically relevant conditions. To keep as many entries as possible temperatures higher than 293K, solvents containing salt solutes, and pH ranging from 5.5 - 8.5 were allowed. The pH range will increase error due to functional groups having different charges at different pH levels however, increased the size of the dataset considerably.\n",
      "\n",
      "-Seperated pH from sovlent column and added to new column. pHs were reported as numerical values, ranges, and maxes and had to be dealt with seperately.\n",
      "\n",
      "-Removed samples with solvents other than water\n",
      "\n",
      "-Several types of molecules were removed, specifcally those containing ions (dianions), which descriptor calculators cannot account for\n",
      "\n",
      "-several columns data types were converted from imported strings to floats\n",
      "\n",
      "-Samples with different additives to the solvent were removed (i.e. HCl, MeOH, H2SO4)\n",
      "\n",
      "-Samples were goruped by host and guest molecules prior to calculating average values for reported variables to remove duplicates.\n",
      "\n",
      "Plans for the next update:\n",
      "\n",
      "-Download .sdf files for molecules and calculate molecular descriptors using either mordred and rdkit toolkit or PaDEL\n",
      "\n",
      "-Begin exploring relationships between calculated descriptors and reported affinity values\n",
      "\n",
      "Questions:\n",
      "\n",
      "-Perhaps not a question but a very helpful excercise for me would be a 1 hour workshop on how to best utilize R and knit to create more complicated documents such as including references and bibliographies or more complicated mathemaical equations. If you could point me to a cheat sheet or in a direction that offers useful information in a condendsed format to reference it would be appreciated for future use.\n",
      "\n",
      "6 Update 1\n",
      "\n",
      "• Current Work:\n",
      "\n",
      "-Quick note- my dataset is contained in approximately 40 pages of poorly formatted PDF tables of three seperate polymers. I use python in this project due to the availability of various molecular descriptor calculators (which will serve as input features in later models) and tools libraries available (rdkit, mordred, and pubchempy).\n",
      "\n",
      "-Excel's 'Get Data from PDF' feature was tried next with better results however inconsistencies in the loaded tables (i.e. multiple columns merged into a single one leaving another blank) were present. Files were saved as .csv files for ease of loading.\n",
      "\n",
      "-A python script was created to scrape tables from PDF's using py-tabula (a python wrapper of the java tabula). Due to the poor formatting of the tables, py-tabula was not able to recognize seperation between columns as well as between rows.\n",
      "\n",
      "-Python script to begin cleaning the dataframe (in conjunction with pandas library) was created. A function was created to seperate conjoined columns and correct values in each column.\n",
      "\n",
      "-While manually inspecting and cleaning the data set after columns had been seperated, it was noticed that several values had been incorrectly loaded into wrong rows due to some rows having uneven spacing and multiline entries. A function to identify pages where there are inconsistencies was created in the data cleaning script however not yet completed.\n",
      "\n",
      "Plans for the next update:\n",
      "\n",
      "-Finish script to double check for inconsistencies within the imported dataframes.\n",
      "\n",
      "-Use rdkit and mordred for descriptor calculation before beginning data exploration (molecular descriptors are the independent variables in this project and binding affinity is the target). Of particular interest for this project is the exploration of relationships between molecular descriptors between the polymer (host) and molecule (guest) in the host/guest ineractions.\n",
      "\n",
      "-Implement functions from scripts that I have previsouly created to download .SDF for all molecules as well as the model polymers from pubchem.\n",
      "\n",
      "Questions:\n",
      "\n",
      "-What other options are available for scraping tables from PDFs into workable dataframes?\n",
      "\n",
      "Reference the sections and figures you are dicussing here\n",
      "\n",
      "7 Excuetive Summary\n",
      "\n",
      "Summarize the key (This could be a bulleted list)\n",
      "\n",
      "-information about your data set\n",
      "\n",
      "-findings from EDA\n",
      "\n",
      "-major data cleaning\n",
      "\n",
      "-Model output\n",
      "\n",
      "-Overall conclusions\n",
      "\n",
      "8 Abstract\n",
      "\n",
      "Summary of the nature, finding and meaning of your data analysis project.\n",
      "\n",
      "1 paragraph written summary of your data analysis project\n",
      "\n",
      "9 Introduction\n",
      "\n",
      "Biomedical implants have become commonplace in medical procedures taking the form of; orthopedic replacements, drug elution devices, and even cosmetic enhancements. Often these devices implement polymer materials in the form of coatings, adhesives, or for mechanical properties. These polymers are commonly used due to their tunable physical (mechanical strength) and chemical (degredation and biocompatable) properties. A major branch of biomedical implants include the use of devices to deliver drugs to local tissue to prevent issues such as infection or immune response. Previsouly these devices solely used either diffusion or degredation mechanisms to deliver loaded drugs. Recently, drug delivery utilizing the affinity between polymer matrixes and desired drugs have been shown to offer a long term and tunable drug release with some showing even a 'holy grail' for treatment of chronic conditions, reloadable properties. These polymers offer unique binding sites like those of the hydrophobic 'pocket' of various cyclodextrins where drugs will bind tightly, but reversibly. Depending on the affinity, bound drugs will slowly unbind and diffuse out to surrounding tissue. To 'reload' one of these devices, a bolus injection near the matrix will cause a large portion of the drug to sequester into the material due to the high affinity. It was, until recently, thought that most polymers did not offer this 'reloading' mechanism however, polymers already being used in devices have been proven to exhibit some level of reloading. Due to the ever increasing number of individuals with some form of biomedical implant containing a polymer as well as the increasing level of pharmaceutical usage, high affinity combinations may lead to systemically administered drugs becoming localized in polymeric devices.\n",
      "\n",
      "Localization of systemically administered drugs may appear to some as a minor inconvience in drug dosing however, if the pharmaceutical being administered is exceedingly toxic, such as chemotherapy agents, or reactive to polymer matrixes, the health of the patient and device integrity may be compromised. It has already been shown that doxorubicin, a potent chemotherapy drug known as the 'red devil', shows affinity to commonly used polylactic acid polymers causing loading into polymer matrixes. There is currently little research into predicting affinity interactions between polymers and drugs beyond simple models predicting affinity for several single polymers. A model capable of predicting affinity between a variety of polymers and small molecule drugs is needed to identify high affinity combinations.\n",
      "\n",
      "The data being used was taken from a comprehensive compilation of binding data created by Rekharsky Et al. consisting of three different forms of cyclodextrins serving as model polymers due to the lack of affinity data available for other polymers. Cyclodextrins have been investigated for several decades due to their unique\n",
      "\n",
      "hydrophobic pocket capable of delivering hydrophobic drugs and thus have a multitude of publications report binding affinity for various small molecules. Binding affinity values consist of four measures, the change in Gibb's free energy, the change in enthalpy, the change in entropy, and log k (association constant) of binding. These four measures, most importantly the Gibb's free energy change, will serve as target or response values in built models. If the Gibb's free energy change of the complexation between the cyclodextrin, host, and drug, guest, is negative, the drug will spontaneously partition itself in the polymer matrix. The model building built will be a Quatntitative Structure Activity Relationship, where the variables of the model will be molecular descriptors for both the drug and polymer. These molecular descriptors will be calculated using a molecular descriptor calculator such as Mordred or PaDEL.\n",
      "\n",
      "Currently there are only three polymers with available binding affinity; alpha-, beta-, and gamma-cyclodextrin. To build a more robust model, it would be beneficial to inculde a wider variety of polymers as well as a wider variety of small molecule drugs. As this is a portion of my PhD work, I will hopefully be collecting more data during the semester for three more polymers commonly used in biomaterials; polylactic acid (PLA), polyglycolic acid (PGA), and poly(lactic-co-glycolic acid) (PLGA) using surface plasmon resonance for validation prior to high throughput data using a high thoughput surface plasmon resonance machine.\n",
      "\n",
      "10 Data Science Methods\n",
      "\n",
      "To be applied (such as image processing, time-series analysis, spectral analysis etc\n",
      "\n",
      "Define critical capabilities and identify packages you will draw upon\n",
      "\n",
      "11 Exploratory Data Analysis\n",
      "\n",
      "11.1 Explanation of your data set\n",
      "\n",
      "How many variables?\n",
      "\n",
      "How many levels of factors for factor variables?\n",
      "\n",
      "What are the data classes?\n",
      "\n",
      "Is your data suitable for a project analysis?\n",
      "\n",
      "Write you databook, defining variables, units and structures\n",
      "\n",
      "11.2 Data Cleaning\n",
      "\n",
      "#%% Data cleaning import pandas as pd #adds dataframe functionality to python import numpy as np #adds matrix/vector mathematics #Import dataset data = pd.read_csv(\"dataset.csv\") #fix two joined columns def column_fixer(df, column, desired_num_char, column_target):\n",
      "\n",
      "for i in range(0, df.shape[0]): #loop through all entries in column if len(str(df.loc[i][column])) == desired_num_char: pass else : temp = df.loc[i][column] #store temp entry df.at[i, column] = temp[0:desired_num_char] #cut and store temp df.at[i, column_target] = temp[desired_num_char:] #store log k return df #returned dataframe with fixed columns data = column_fixer(data, \"t\", 3, \"log k\") #use function on dataframe def num_entry_fixer(df, columns): #fix incorrectly imported string symbols for col in columns: #loop through desired columns for i in range(0, df.shape[0]): #loop through all entries if '(' in str(df.loc[i][col]): #test if incorrect symbol present temp = df.loc[i][col].split(sep = '(') #split and store temp df.at[i, col] = float(temp[0]) #join with +/del (temp) else : #pass if correct pass return df data = num_entry_fixer(data, data.columns[4 : 8]) #run function on columns def string_cor(df): #used to remove whitespace and ensure all lowercase for col in df.columns: for i in range(0, df.shape[0]): df.at[i, col] = str(df.loc[i][col]).replace(\" \", \"\").lower() return df data = string_cor(data) #check solvents, only want biologically relevant conditions def solvent_check(df, solvent_col): for i in range(0, df.shape[0]): if \"h_{2}o\" in df.loc[i][solvent_col]: #check if solvent is water pass else : df = df.drop(i) return df data = solvent_check(data, \"solvent\") data.reset_index(drop = True, inplace = True) #reindex after dropping rows #add new column, ph, and seperate\n",
      "\n",
      "phs = [] for i in range(0, data.shape[0]): if \"ph\" in data.loc[i][\"solvent\"]: #if ph is listed add to list index = data.loc[i][\"solvent\"].find(\"ph\") phs.append(data.loc[i][\"solvent\"][index + 2:].replace(\")\", \"\")) data.at[i, \"solvent\"] = data.loc[i][\"solvent\"][0 : index] if len(data.loc[i][\"solvent\"]) == 7: data.at[i, \"solvent\"] = data.loc[i][\"solvent\"].replace(\"(\", \"\") else : data.at[i, \"solvent\"] = data.loc[i][\"solvent\"][0: -1] + \")\" elif data.loc[i][\"solvent\"] == \"h_{2}o\": #if only water ph = 7 phs.append('7.0') else : phs.append('n/a') #if other chemicals present list as n/a del (i, index) data[\"phs\"] = phs del (phs) #check phs, if not between 6-8 drop entry def is_float(string): #T/F funciton stating if string is float try : return float(string) except ValueError : return False #check ph entry, some are listed as ranges or maximums, drop those out of range def ph_check(df): for i in range(0, df.shape[0]): if df.loc[i][\"phs\"] == \"n/a\": #pass with other solvents, corrected l8r pass elif \"-\" in df.loc[i][\"phs\"]: #range given, use average for range temp = df.loc[i][\"phs\"].split(sep = \"-\") temp = list(map(float, temp)) #change datatype of list elements test = sum(temp) / len(temp) if 5.5 <= test <= 8.5: pass else : df = df.drop(i) elif is_float(df.loc[i][\"phs\"]): #if float value, determine if in range if 5.5 <= float(df.loc[i][\"phs\"]) <= 8.5: pass else :\n",
      "\n",
      "df = df.drop(i) elif \"<\" in df.loc[i][\"phs\"]: #phs maxes, check if max in range if 5.5 <= float(df.loc[i][\"phs\"][1:]) <= 8.5: pass else : df = df.drop(i) else : pass return df data = ph_check(data) data.reset_index(drop = True, inplace = True) #remove entries for given list containing undesirable def entry_cleaner(df, column, nono): for i in range(0, df.shape[0]): if any(no in df.loc[i][column] for no in nono): #check if any bad terms df = df.drop(i) #drop if bad terms in given column else : pass df.reset_index(drop = True, inplace = True) return df #remove ions data = entry_cleaner(data, \"guest\", [\"monoanion\", \"dianion\", \"hcl\", \"anion\"]) #remove entries which have undesirable additives in solution data = entry_cleaner(data, \"solvent\", [\"hcl\", \"h_{2}so_{4}\",\"naoh\", \"urea\", \"ch_{3}cn\", \"meoh\", \"na_{2}so_{4}\", \"dmso\"]) #edit datatype of several columns currently stored as strings data = data.astype({ \"log k\": \"float\", \"delta g\": \"float\", \"delta h\": \"float\", \"t delta s\": \"float\" }) #group data by host and guest then find averages of entries, eliminating dupes data = data.groupby([\"host\", \"guest\"]).agg( log_k_avg = (\"log k\", np.mean), gibbs_avg = (\"delta g\", np.mean), enthalpy_avg = (\"delta h\", np.mean), entropy_avg = (\"t delta s\", np.mean) ) print(data.head(10))\n",
      "\n",
      "##\n",
      "\n",
      "|    | 0        | 1                                 | 2     | 3   | 4          |\n",
      "|---:|:---------|:----------------------------------|:------|:----|:-----------|\n",
      "|  0 | ## host  | guest                             |       | ... |            |\n",
      "|  1 | ## alpha | (1-methylbutyl)ammonium           | 1.290 | ... | -3.800000  |\n",
      "|  2 | ##       | (1-methylheptyl)ammonium          | 3.053 | ... | -2.400000  |\n",
      "|  3 | ##       | (1-methylhexyl)ammonium           | 2.619 | ... | -3.333333  |\n",
      "|  4 | ##       | (1r,2r)-(-)-pseudoephedrine       | 1.270 | ... | -10.500000 |\n",
      "|  5 | ##       | (1r,2s)-(-)-ephedrine             | 1.230 | ... | -8.600000  |\n",
      "|  6 | ##       | (1s,2r)-(+)-ephedrine             | 1.260 | ... | -7.700000  |\n",
      "|  7 | ##       | (1s,2s)-(+)-pseudoephedrine       | 1.300 | ... | -11.000000 |\n",
      "|  8 | ##       | (2,5-dimethoxyphenethyl)-ammonium | 1.540 | ... | -10.000000 |\n",
      "|  9 | ##       | (3,4-dimethoxyphenethyl)-ammonium | 0.900 | ... | -3.900000  |\n",
      "| 10 | ## ##    | (3-methoxyphenethyl)ammonium      | 1.350 | ... | -11.300000 |\n",
      "| 11 | ## [10   | rows x 4 columns]                 |       |     |            |\n",
      "\n",
      "11.3 Data Vizualizations\n",
      "\n",
      "Vizualizations of your data\n",
      "\n",
      "11.4 Variable Correlations\n",
      "\n",
      "Pairwise correlation plots, etc.\n",
      "\n",
      "12 Statistical Learning: Modeling & Prediction\n",
      "\n",
      "DSCI 451 will accomplish at least 1 simple linear model (or simple logistic model)\n",
      "\n",
      "DSCI 352/352M/452 requires the appropriate modeling for your data set including machine learning\n",
      "\n",
      "Types of modeling to try\n",
      "\n",
      "Statistical prediction/modeling\n",
      "\n",
      "Model selection\n",
      "\n",
      "Cross-validation, Predictive R2\n",
      "\n",
      "Interpret results\n",
      "\n",
      "Challenge results\n",
      "\n",
      "13 Discussion\n",
      "\n",
      "Discussion of the answers to the data science questions framed in the introduction\n",
      "\n",
      "log_k_avg\n",
      "\n",
      "...\n",
      "\n",
      "entropy_avg\n",
      "\n",
      "14 Conclusions\n",
      "\n",
      "15 Acknowledgments\n",
      "\n",
      "16 References\n",
      "\n",
      "Include a bib file in the markdown report\n",
      "\n",
      "Or hand written citations.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeb3070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "pages = []\n",
    "\n",
    "for page in doc._.pages:\n",
    "    pages.append(page)\n",
    "    print(page[0].page_no)\n",
    "type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "80356f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f367d67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference the sections and figures you are dicussing here\n",
      "1019 to 2737\n",
      "|    | 0                                                                                | 1   |\n",
      "|---:|:---------------------------------------------------------------------------------|:----|\n",
      "|  0 | 13 Discussion                                                                    | 10  |\n",
      "|  1 | 14 Conclusions                                                                   | 11  |\n",
      "|  2 | 15 Acknowledgments                                                               | 11  |\n",
      "|  3 | 16 References                                                                    | 11  |\n",
      "|  4 | #Please know that you can use a html output but you need to keep the sectioning. |     |\n",
      "|  5 | #Please Reference your figures and tables so that it is readable                 |     |\n",
      "|  6 | #Each update is important to keep for grading                                    |     |\n",
      "\n",
      "1 Update 6\n",
      "\n",
      "Please put a bulleted list of things you have accomplished since the last update\n",
      "\n",
      "-Include things that didn't work but you tried\n",
      "\n",
      "-Questions that you might have on your project.\n",
      "\n",
      "-Things you are planning on doing\n",
      "\n",
      "Reference the sections and figures you are dicussing here\n",
      "\n",
      "2 Update 5\n",
      "\n",
      "Please put a bulleted list of things you have accomplished since the last update\n",
      "\n",
      "-Include things that didn't work but you tried\n",
      "\n",
      "-Questions that you might have on your project.\n",
      "\n",
      "-Things you are planning on doing\n",
      "\n",
      "Reference the sections and figures you are dicussing here\n",
      "\n",
      "3 Update 4\n",
      "\n",
      "Please put a bulleted list of things you have accomplished since the last update\n",
      "\n",
      "-Include things that didn't work but you tried\n",
      "\n",
      "-Questions that you might have on your project.\n",
      "\n",
      "-Things you are planning on doing\n",
      "\n",
      "Reference the sections and figures you are dicussing here\n"
     ]
    }
   ],
   "source": [
    "page = pages[1]\n",
    "page_spans = page[1]\n",
    "page_start = page_spans[0].start_char\n",
    "print(page_spans[-1])\n",
    "page_end = page_spans[-1].end_char\n",
    "print(str(page_start) + \" to \" + str(page_end))\n",
    "md = doc.text\n",
    "print(md[page_start:page_end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f027bdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3d723ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "md = doc.text\n",
    "page_1 = md[page_start:page_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "14874bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Predictors of Binding Affinity Between Small Molecule Drugs and Model Polymers\\n\\nJacob Kerner\\n\\n12 March, 2021\\n\\nContents\\n\\n|    | 0                                  |   1 |\\n|---:|:-----------------------------------|----:|\\n|  0 | 1 Update 6                         |   2 |\\n|  1 | 2 Update 5                         |   2 |\\n|  2 | 3 Update 4                         |   2 |\\n|  3 | 4 Update 3                         |   3 |\\n|  4 | 5 Update 2                         |   3 |\\n|  5 | 6 Update 1                         |   4 |\\n|  6 | 7 Excuetive Summary                |   5 |\\n|  7 | 8 Abstract                         |   5 |\\n|  8 | 9 Introduction                     |   5 |\\n|  9 | 10 Data Science Methods            |   6 |\\n| 10 | 11 Exploratory Data Analysis       |   6 |\\n| 11 | 11.1 Explanation of your data set  |   6 |\\n| 12 | 11.2 Data Cleaning . . . . . . . . |   6 |\\n| 13 | 11.3 Data Vizualizations . . . . . |  10 |\\n| 14 | 11.4 Variable Correlations . . . . |  10 |\\n\\n12 Statistical Learning: Modeling & Prediction'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
